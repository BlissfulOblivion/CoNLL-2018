{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoNLL MAIN PROGRAM\n",
    "## Encoder-Decoder with Attention\n",
    "### Current archetype: BiGRU with Attention\n",
    "--------------------------\n",
    "#### Plan:\n",
    "1. Finish commenting -- **DONE**\n",
    "2. Edit evaluation functions -- **DONE**\n",
    "3. Test with current design (get dev data and test on dev data) -- **DONE**\n",
    "4. Incorporate tags in input -- **DONE**\n",
    "5. Test with tags in input -- **DONE**\n",
    "6. Convert GRU to LSTM -- **CANCELED**\n",
    "7. Test with LSTM structure -- **CANCELED**\n",
    "8. Edit for BiRNN structure (GRU) -- **DONE**\n",
    "9. Test with fully developed structure\n",
    "10. Discuss future possibilities\n",
    "--------------------------\n",
    "#### Questions:\n",
    "1. What does .view() do? **Answer**: resizes tensors (see section 2 of tests)\n",
    "2. How does super() work with pytorch? **Answer**: Basic inheritance\n",
    "3. What is squeeze/unsqueeze? **Answer**: Squeeze squishes any one-sized dims in a tensor, unsqueeze adds a 1-sized dim at a given position in the tensor\n",
    "4. What does .size() do? **Answer**: returns size of tensor\n",
    "5. What is topk? **Answer**: Returns top k largest values of tensor along a specified dim\n",
    "--------------------------\n",
    "#### Need help with spots:\n",
    "1. Line 38 in \"# Training loop definition\": How to resize tensors so they can be concatenated? Purpose: to concatenate context (morphological tags) tensor to decoder hidden state (this is where it is initiated) -- **FIXED**\n",
    "2. In \"# Decoder RNN with attention\" and elsewhere: How to reshape vectors such that decoder hidden state with context included can be run through torch.bmm with encoder output without losing information? -- **FIXED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''      ANNOTATION KEY      '''\n",
    "# S/E = self explanatory\n",
    "# ??? = uncertain of meaning/purpose\n",
    "# TUOP = texual update of progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division # ???\n",
    "from io import open # For opening files\n",
    "import unicodedata # To convert to ASCII -- necessary?\n",
    "import string # ???\n",
    "import re # For normalizing text -- necessary?\n",
    "import random # For randomizing samples of data\n",
    "\n",
    "import torch # Imports pytorch\n",
    "import torch.nn as nn # Imports nn from pytorch\n",
    "from torch import optim # For optimization (SGD)\n",
    "import torch.nn.functional as F # For linear functions in neural nets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Sets what processor to use (GPU/CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up language classes for indexing characters\n",
    "\n",
    "# Start and end of word tokens\n",
    "SOW_token = 0\n",
    "EOW_token = 1\n",
    "\n",
    "# Class to set up lemmas and inflected words -- find new name maybe?\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name # S/E\n",
    "        # Creates an index for char --> index, char count, and index --> char\n",
    "        #   plus total number of unique chars\n",
    "        self.char2index = {}\n",
    "        self.char2count = {}\n",
    "        self.index2char = {0: \"SOW\", 1: \"EOW\"}\n",
    "        self.n_chars = 2  # Count SOW and EOW\n",
    "\n",
    "    # Adds all characters in word to Lang\n",
    "    def addWord(self, word, tags=None):\n",
    "        word = list(word)\n",
    "        if tags != None:\n",
    "            word += tags\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    # Adds char information to/creates indexes and counts for Lang\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in language and setting\n",
    "# Outputs lemma Lang, inflected word Lang, and pairs plus tags\n",
    "\n",
    "def readLangs(lang, setting):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file based on input language and setting (low/med/high) and split into lines\n",
    "    lines = open('%s_%s.txt' % (lang, setting), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs of lemmas/words and tags; normalize\n",
    "    pairs = [[s for s in l.split('\\t')[:2]] for l in lines] # Makes lemma/word pairs\n",
    "    tags = [l.split('\\t')[2].split(';') for l in lines] # Makes list of tags to add to input\n",
    "    pairs_tags = list(zip(pairs,tags)) # Zips matching lemma/word pairs and tag set\n",
    "\n",
    "    # Make Lang instances\n",
    "    lemmas = Lang(\"lemmas\") # S/E\n",
    "    inflected_words = Lang(\"inflected words\") # S/E\n",
    "\n",
    "    return lemmas, inflected_words, pairs_tags # S/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to find maximum length for a word to normalize input length\n",
    "#    runs through all lemma/word pairs to find longest string and returns the length of that string\n",
    "\n",
    "def findMax(pairs):\n",
    "    max_length = 0\n",
    "    for line in pairs:\n",
    "        if len(line[0][0]) > max_length:\n",
    "            max_length = len(line[0][0])\n",
    "        if len(line[0][1]) > max_length:\n",
    "            max_length =len(line[0][1])\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 100 lemma/word pairs\n",
      "Finding maximum string length...\n",
      "Maximum string length: 23\n",
      "Counting lemmas/words...\n",
      "Counted lemmas/words:\n",
      "lemmas 54\n",
      "inflected words 31\n",
      "(['aíochtlann', 'leis an aíochtlann'], ['N', 'DAT', 'SG', 'DEF'])\n"
     ]
    }
   ],
   "source": [
    "# Sets up lemmas, words, lemma/word-pairs and tags pairs, and maximum string length\n",
    "\n",
    "def prepareData(lang, setting):\n",
    "    lemmas, inflected_words, pairs_tags = readLangs(lang, setting) # S/E'\n",
    "    print(\"Read %s lemma/word pairs\" % len(pairs_tags)) # TUOP\n",
    "    print(\"Finding maximum string length...\") # TUOP\n",
    "    max_length = findMax(pairs_tags) # S/E\n",
    "    print(\"Maximum string length: %s\" % max_length) # TUOP\n",
    "    print(\"Counting lemmas/words...\") # TUOP\n",
    "    for pairtag in pairs_tags:\n",
    "        lemmas.addWord(pairtag[0][0],pairtag[1]) # S/E\n",
    "        inflected_words.addWord(pairtag[0][1]) # S/E\n",
    "    print(\"Counted lemmas/words:\") # TUOP\n",
    "    print(lemmas.name, lemmas.n_chars) # TUOP\n",
    "    print(inflected_words.name, inflected_words.n_chars) # TOUP\n",
    "    return lemmas, inflected_words, pairs_tags, max_length # S/E\n",
    "\n",
    "\n",
    "lemmas, inflected_words, pairs_tags, max_length = prepareData('irish', 'low') # S/E\n",
    "print(random.choice(pairs_tags)) # TUOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder RNN\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__() # S/E\n",
    "        self.hidden_size = hidden_size # Sets size of hidden layer\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size) # Sets embedding layer\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True) # Sets bidirectional GRU\n",
    "\n",
    "    def forward(self, input, hidden): # Computes forward propogation\n",
    "        embedded = self.embedding(input).view(1, 1, -1) # Reshapes tensor\n",
    "        output = embedded # S/E\n",
    "        output, hidden = self.gru(output, hidden) # Runs output and hidden through GRU\n",
    "        return output, hidden # S/E \n",
    "\n",
    "    def initHidden(self): # Used to initiate hidden layer dims\n",
    "        return torch.zeros(2, 1, self.hidden_size, device=device) # Returns torch tensor of zeros in given dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder RNN with Attention\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, max_length, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__() # S/E\n",
    "        self.hidden_size = hidden_size # Sets hidden layer size\n",
    "        self.output_size = output_size # Sets output layer size\n",
    "        self.dropout_p = dropout_p # Sets dropout rate\n",
    "        self.max_length = max_length # Sets maximum string length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size) # Sets embedding layer\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length) # Sets attention mechanism\n",
    "        # Combines attention mecahanims parts?\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) \n",
    "        self.dropout = nn.Dropout(self.dropout_p) # Implements dropout\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size) # Sets GRU\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size) # Sets linear output function\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs): # Forward propogation\n",
    "        embedded = self.embedding(input).view(1, 1, -1) # Reshapes embedding tensor for hidden layer shape\n",
    "        embedded = self.dropout(embedded) # Implements dropout of embedded layer\n",
    "\n",
    "        # Sets attention weights (read more)\n",
    "        #    takes softmax of linear attention functions from concatenated embedding layer and hidden layer\n",
    "        #    dim=1 is the dimension along which softmax is applied. why 0 index? (figure out later)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        # Matrix multiplication of the attention weights and the encoder outputs\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        # ??? Concatenates embedding tensors and attention, but why? and why 0 index?\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1) \n",
    "        output = self.attn_combine(output).unsqueeze(0) # Figure all this attention stuff out later\n",
    "\n",
    "        output = F.relu(output) # Runs output through ReLU function\n",
    "        output, hidden = self.gru(output, hidden) # Runs output and hidden state through GRU\n",
    "\n",
    "        # Runs output through linear function, then log softmax; why 0 index and why dim 1?\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1) \n",
    "        return output, hidden, attn_weights # S/E\n",
    "\n",
    "    def initHidden(self): # Used to initiate hidden layer dims\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device) # Returns torch tensor of zeros in given dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates tensors from indexes\n",
    "\n",
    "def indexesFromWord(Lang, word): # Accesses character indexes of input word from Lang\n",
    "    return [Lang.char2index[char] for char in word] # S/E\n",
    "\n",
    "def tensorFromWord(Lang, word): # Creates tensor from input word\n",
    "    indexes = indexesFromWord(Lang, word) # Gets list of indexes of characters in word\n",
    "    indexes.append(EOW_token) # Adds end of word token\n",
    "    # Returns tensor based on character indexes input\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) # S/E\n",
    "\n",
    "def indexesFromTags(Tags, tags): # Accesses tag indexes of input tags from Tags\n",
    "    return [Tags.tag2index[tag] for tag in tags] # S/E\n",
    "\n",
    "def tensorFromTags(Tags, tags):\n",
    "    indexes = indexesFromTags(Tags, tags) # Gets list of indexes of characters in word\n",
    "    # Returns tensor based on character indexes input\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) # S/E\n",
    "\n",
    "def tensorsFromPair(pair): # Creates tensor from lemma/word pair\n",
    "    input_tensor = tensorFromWord(lemmas, pair[0][0]) # Creates input tensor\n",
    "    target_tensor = tensorFromWord(inflected_words, pair[0][1]) # Creates target output tensor\n",
    "    return (input_tensor, target_tensor) # S/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop defintion\n",
    "\n",
    "teacher_forcing_ratio = 0.5 # Sets probability of teacher forcing occuring\n",
    "\n",
    "# Defines train function; following is each variable's function, in order:\n",
    "#    input_tensor = input tensor\n",
    "#    target_tensor = target tensor\n",
    "#    encoder = instance of EncoderRNN\n",
    "#    decoder = instance of AttnDecoderRNN\n",
    "#    encoder_optimizer, decoder_optimizer = optimization algorithm (in this case SGD)\n",
    "#    max_length = maximum string length\n",
    "#    criterion = loss function (in this case negative log loss)\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\\\n",
    "          decoder_optimizer, max_length, criterion):\n",
    "    encoder_hidden = encoder.initHidden() # Returns hidden layer dim for encoder\n",
    "\n",
    "    encoder_optimizer.zero_grad() # Resets optimizer\n",
    "    decoder_optimizer.zero_grad() # Resets optimizer\n",
    "\n",
    "    input_length = input_tensor.size(0) # Input tensor length\n",
    "    target_length = target_tensor.size(0) # Target tensor length\n",
    "\n",
    "    # Sets encoder output dims\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size * 2, device=device) \n",
    "\n",
    "    loss = 0 # Sets/resets loss to 0\n",
    "\n",
    "    for ei in range(input_length): # Tensor inputs\n",
    "        # Calculates encoder output and hidden state based on input tensor and encoder hidden state\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0] # Stores encoder outputs (figure out later why these indexes)\n",
    "    \n",
    "    # Initiates decoder input with start of word token\n",
    "    decoder_input = torch.tensor([[SOW_token]], device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden.view(1,1,-1) # Initiates decoder hidden state with final encoder hidden state\n",
    "\n",
    "    # Randomly decide when to or not to use teacher forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False \n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length): # Iterates through target tensors\n",
    "            # Runs input, decoder hidden state, and encoder outputs through decoder\n",
    "            #    and sets decoder output, hidden state, and attention to output of decoder\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di]) # Calculates loss\n",
    "            # Teacher forcing: makes next input the target input instead of guessed output\n",
    "            decoder_input = target_tensor[di]\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # Runs input, decoder hidden state, and encoder outputs through decoder\n",
    "            #    and sets decoder output, hidden state, and attention to output of decoder\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1) # ??? Generator? but why topv?\n",
    "            # \"detach from history as input\" -- what does this mean/do?\n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di]) # Calculates loss\n",
    "            if decoder_input.item() == EOW_token: # S/E\n",
    "                break\n",
    "\n",
    "    loss.backward() # S/E\n",
    "\n",
    "    encoder_optimizer.step() # S/E\n",
    "    decoder_optimizer.step() # S/E\n",
    "\n",
    "    return loss.item() / target_length # S/E\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates timer functions; Not totally relevant\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff for plotting; Mess with later\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines training iteration function\n",
    "\n",
    "# Defines training iteration function; explanation of each input vairable:\n",
    "#    encoder = instance of EncoderRNN\n",
    "#    decoder = instance of AttnDecoderRNN\n",
    "#    n_iters = number of iterations\n",
    "#    print_every=# = print TUOP every # iterations\n",
    "#    plot_every=# = plot TUOP every # iterations\n",
    "#    learning_rate=# = S/E\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time() # Starts timer\n",
    "    plot_losses = [] # ??? Probably for plotting -- deal with later\n",
    "    print_loss_total = 0  # Reset every print_every -- ??? I think: resets loss total to print\n",
    "    plot_loss_total = 0  # Reset every plot_every -- ??? I think: resets loss total to plot\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) # Sets encoder optimizer\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) # Sets decoder optimizer\n",
    "    # Sets up training data of tensors from \n",
    "    #    randomized selections of lemma/word pairs for the number of iterations\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs_tags)) \n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss() # Sets loss function\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1] # Selects a training pair\n",
    "        input_tensor = training_pair[0] # Takes input string's tensor\n",
    "        target_tensor = training_pair[1] # Take target string's tensor\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, max_length, criterion) # S/E\n",
    "        print_loss_total += loss # Adds current loss to total loss for printing\n",
    "        plot_loss_total += loss # Adds current loss to toal loss for plotting\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every # Print avg of loss over iterations\n",
    "            print_loss_total = 0 # Resets total loss to print\n",
    "            # TUOP in terms of % complete and time taken, etc\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0: # Plot stuff; check out later\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses) # Shows plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation code\n",
    "\n",
    "# Defines evalutate:\n",
    "#    encoder, decoder = instances of EncoderRNN, AttnDecoderRNN\n",
    "#    lemma = word\n",
    "#    max_length = maximum string length\n",
    "def evaluate(encoder, decoder, lemma, max_length):\n",
    "    with torch.no_grad(): # Keeps it from training\n",
    "        input_tensor = tensorFromWord(lemmas, lemma) # Creates input tensor\n",
    "        input_length = input_tensor.size()[0] # S/E\n",
    "        encoder_hidden = encoder.initHidden() # Sets up hidden layer dims\n",
    "\n",
    "        # Sets up encoder outputs dims and sets them to zeros\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length): # Encoder input\n",
    "            # Runs input tensor and encoder hidden state through encoder\n",
    "            #    and sets encoder output and hidden state\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            # Adds encoder output to list of encoder outputs -- details later\n",
    "            encoder_outputs[ei] += encoder_output[0, 0] \n",
    "            \n",
    "\n",
    "        # Sets encoder input to tensor of start of word token\n",
    "        decoder_input = torch.tensor([[SOW_token]], device=device)  \n",
    "\n",
    "        decoder_hidden = encoder_hidden # Sets decoder hidden state to encoder hidden state\n",
    "        \n",
    "        decoded_chars = [] # Initiates list of decoded words\n",
    "        # ??? Sets decoder attentions?\n",
    "        #    To tensor of zeros of maximum string length as dimensions? Why those dims?\n",
    "        #    Figure that out later\n",
    "        decoder_attentions = torch.zeros(max_length, max_length) \n",
    "\n",
    "        for di in range(max_length): # Decoder input\n",
    "            # Runs input tensor and decoder hidden state through decoder\n",
    "            #    and sets decoder output and hidden state\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data # ??? .data? Probably the generator\n",
    "            topv, topi = decoder_output.data.topk(1) # ??? topv, topi? .data.topk?\n",
    "            if topi.item() == EOW_token: # Breaks if top word is end of word token(? what is topi?)\n",
    "                decoded_chars.append('<EOW>')\n",
    "                break\n",
    "            else:\n",
    "                # Appends topi(?) word to decoded word list\n",
    "                decoded_chars.append(inflected_words.index2char[topi.item()]) \n",
    "                \n",
    "            decoder_input = topi.squeeze().detach() # Details later\n",
    "\n",
    "        return decoded_chars, decoder_attentions[:di + 1] # Returns decoded word and attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly evaluate words\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, pairs_tags, n=10): # n=# = number of samples to evaluate\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs_tags)\n",
    "        print('>', pair[0][0])\n",
    "        print('=', pair[0][1])\n",
    "        output_chars, attentions = evaluate(encoder, decoder, pair[0][0], pair[1], max_length)\n",
    "        output_word = ''.join(output_chars)\n",
    "        print('<', output_word)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 49s (- 109m 29s) (5000 6%) 1.1876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fbdf6c785fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Executes program\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-c1b3dca29309>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 30\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, max_length, criterion) # S/E\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;31m# Adds current loss to total loss for printing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;31m# Adds current loss to toal loss for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-24f079f5d4f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, max_length, criterion)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Calculates encoder output and hidden state based on input tensor and encoder hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[0;32m---> 30\u001b[0;31m             input_tensor[ei], encoder_hidden)\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Stores encoder outputs (figure out later why these indexes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-12c369ae1b69>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Computes forward propogation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reshapes tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m \u001b[0;31m# S/E\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Runs output and hidden through GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    106\u001b[0m         return F.embedding(\n\u001b[1;32m    107\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                  [ 0.6262,  0.2438,  0.7471]]])\n\u001b[1;32m   1063\u001b[0m     \"\"\"\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256 # Hidden layer size\n",
    "# Initiates instance of EncoderRNN with input size of number of unique chars? and hidden size as above\n",
    "encoder1 = EncoderRNN(lemmas.n_chars, hidden_size).to(device) \n",
    "# Initiates instance of AttnDecoderRNN with hidden size as above, output size of number of unique chars?\n",
    "#    the maximum string length, and the dropout rate\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size * 2, inflected_words.n_chars, max_length, dropout_p=0.1).to(device)\n",
    "\n",
    "# Executes program\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1, pairs_tags) # Evaluates random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements evaluation of system\n",
    "\n",
    "output_chars, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"amhran\", max_length) # Outputs word and attentions from system given input word\n",
    "plt.matshow(attentions.numpy()) # Plots attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates plots of attentions and evaluations of system output\n",
    "# DO THIS LATER\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_lemmas, dev_inflected_words, dev_pairs_tags, dev_max_length = prepareData('irish', 'dev') # S/E\n",
    "print(random.choice(pairs_tags)) # TUOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1,dev_pairs_tags) # Evaluates random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST of readLangs\n",
    "# WORKS\n",
    "\n",
    "def readLangs(lang1, setting, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s_%s.txt' % (lang1, setting), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
    "    tags = [l.split('\\t')[2].split(';') for l in lines]\n",
    "    pairs_tags = list(zip(pairs,tags))\n",
    "\n",
    "    # Make Lang instances\n",
    "    lemmas = Lang(\"lemmas\")\n",
    "    inflected_words = Lang(\"inflected words\")\n",
    "\n",
    "    return lemmas, inflected_words, pairs_tags\n",
    "\n",
    "\n",
    "readLangs(\"irish\",\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.range(1, 16)\n",
    "print(a)\n",
    "print(a.size(0))\n",
    "a = a.view(4,4)\n",
    "print(a)\n",
    "print(a.size(1))\n",
    "print(\"\\n----\\n\")\n",
    "b = torch.range(1,27)\n",
    "print(b)\n",
    "print(b.size(0))\n",
    "b = b.view(3,3,3)\n",
    "print(\"1\", b)\n",
    "b = b.unsqueeze(3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"V;3;PL;IMP\"\n",
    "a = list(a)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
